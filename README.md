# 一种自适应的盘古大模型优化方法

本仓库提供了一套针对 **Pangu-Embedded** 系列大模型（1B/7B）在 **华为昇腾 (Ascend) NPU** 平台上的全栈优化方案。涵盖了从权重压缩（W8A16 量化）、结构化剪枝（Taylor 迭代剪枝 + 蒸馏）到投机推理（draft、PLD）以及自适应意图识别框架。

---

## 核心特性

- **W8A16 混合精度量化**：Int8 权重存储，BF16 运行时反量化计算。
- **基于 Taylor 的迭代剪枝**：采用一阶梯度重要性评分，结合 256-bit NPU 硬件对齐，确保物理加速。
- **知识蒸馏**：通过 KL 散度，在高剪枝率下恢复精度。
- **双模投机推理加速**：
  - **Draft Model 方案**：7B 主模型 + 1B 草稿模型协同，提升逻辑一致性。
  - **PLD (Pattern Lookahead Decoding)**：基于 N 元匹配的零耗时草稿生成，最高实现 2 倍速度提升。
- **自适应优化框架**：利用 1B 模型自动识别用户意图，智能推荐最匹配的推理策略。

---

## 技术方案详解

### 1. W8A16 混合精度量化
实现了一种“低功耗存储，高精度计算”的量化方案。
针对线性层权重进行 Int8 量化。在前向传播时，实时将权重还原为 BF16 与激活值进行矩阵乘法。
- **算法逻辑**：计算每通道缩放因子 $Scale = \frac{\max(|W|)}{127}$，将权重映射至 $[-128, 127]$。
- **显存收益**：Pangu-1B 显存占用从 **2.15GB** 降至 **1.34GB**。

### 2. 迭代式 Taylor 剪枝与多维蒸馏
针对 MLP 维度进行结构化移除，通过 5 轮线性调度平滑压缩空间。
- **Taylor 评分**：$Score = |W \cdot \nabla W|$，精准识别对损失函数波动贡献最小的神经元。
- **NPU 对齐**：强制保留维度为 256 的倍数，消除物理层面的硬件 Padding，提升算力利用率。
- **最优配置**：5e-5 学习率 + 线性调度 + KL 蒸馏。

### 3. 投机推理加速 
针对自回归生成的串行瓶颈，提供了两类加速方案：
- **草稿模型方案**：使用 1B 模型作为草稿模型（Draft）预生成K个 Token，7B 主模型进行并行验证，显著提升吞吐量。
- **PLD 方案**：基于 N-Gram 匹配的预测查找解码。利用 NGramMatcher 在历史上下文中检索重复模式，实现零参数消耗的草稿生成。

### 4.自适应优化框架
集成意图识别逻辑，利用 1B 模型自动判断用户任务类型，并根据实验基准（Benchmark）自动推荐最优的量化/剪枝/加速组合策略。

---

## 实验结果

### 量化性能（代码能力）

|       | MBPP  |
| ----- | ----- |
| 原模型   | 54.09 |
| 量化后模型 | 53.31 |

### 剪枝与蒸馏性能 (数学推理)

| MLP层剪枝率 | GSM8K评分 |
| ------- | ------- |
| 4.17%   | 71.87   |
| 8.33    | 69.52   |
| 12.5    | 64.59   |
| 16.67   | 61.87   |
| 20.83   | 61.87   |
### 投机推理加速比 (Tokens/s)
以 Pangu-1B 为例，采用 PLD 方案（N=3, K=4）：

| 模型       |  评测任务  | Baseline 速度 | PLD 速度 |    加速比    |
| :------- | :----: | :---------: | :----: | :-------: |
| Pangu-1B | C-Eval |    21.58    | 41.93  | **1.94x** |
| Pangu-1B |  MMLU  |    21.87    | 43.41  | **1.98x** |

---

## 项目结构

- src/main_distill_prune.py: 核心剪枝与蒸馏实现。
    
- src/main_quantization.py: W8A16 量化器与反量化线性层定义。
    
- src/main_speculative_draft_ceval.py: 基于 Top-K 采样的大-小模型投机解码器。
    
- src/main_speculative_pld.py: 基于 N-Gram 匹配的预测查找解码实现（适配 OpenCompass）。
    
- docs/: 详细的实验报告与技术分析文档。

---

## 环境要求

- **Hardware**: Huawei Ascend 910B/310P NPU
- **Framework**: `torch >= 2.1.0`, `torch_npu`, `transformers >= 4.34.0`
- **CANN**: 华为昇腾 CANN 社区版/商业版

---


## 引用与致谢
本项研究基于盘古大模型系列。感谢华为昇腾提供的计算资源与 `torch_npu` 技术支持。

--- 

**项目维护者**：[湖南大学智能计算系统研究所（IICS）]
**联系方式**：[ding@hnu.edu.cn]
